---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "sifflet_source Resource - terraform-provider-sifflet"
subcategory: ""
description: |-
  A Sifflet source. A source is any system that's monitored by Sifflet.
  ~> Consider adding a lifecycle { prevent_destroy = true } to sifflet_source resources once they are correctly configured. Deleting a source deletes all associated data, including monitors on that source.
---

# sifflet_source (Resource)

A Sifflet source. A source is any system that's monitored by Sifflet.

~> Consider adding a `lifecycle { prevent_destroy = true }` to `sifflet_source` resources once they are correctly configured. Deleting a source deletes all associated data, including monitors on that source.

## Example Usage

```terraform
# The format of the credentials value must match what the source expects.
# See the Sifflet documentation for each source type for details
# about the credential value format.
data "sifflet_credentials" "example" {
  name = "example"
}

# A simple BigQuery data source.
resource "sifflet_source" "example" {
  name        = "example"
  description = "A description"
  credentials = sifflet_credentials.example.name
  parameters = {
    # Pass the parameter block that matches the source type.
    bigquery = {
      project_id         = "project_id"
      dataset_id         = "dataset"
      billing_project_id = "dataset"
    }
  }
}

# Example with more complex parameters.
resource "sifflet_source" "complex" {
  name        = "example"
  description = "A description"
  credentials = sifflet_credentials.example.name
  parameters = {
    snowflake = {
      account_identifier = "accountidentifier"
      database           = "database"
      schema             = "schema"
      warehouse          = "warehouse"
    }
  }
  schedule = "@daily"
  # The timezone can also be a timezone name, e.g. "Europe/Paris".
  timezone = "UTC+1"
  tags = [{
    # Tags attached to the source must already exist before
    # creating the source.
    name = "tag_name"
  }]
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `name` (String) Source name.
- `parameters` (Attributes) Connection parameters. Provide only one nested block depending on the source type. (see [below for nested schema](#nestedatt--parameters))

### Optional

- `credentials` (String) Name of the credentials used to connect to the source. Required for most datasources, except for 'athena', 'dbt' and 'quicksight' sources.
- `description` (String) Source description.
- `schedule` (String) Schedule for the source. Must be a valid cron expression. If empty, the source will only be refreshed when manually triggered.
- `tags` (Attributes List) Tags for the source. For each tag, you can provide either: an ID, a name, or a name + a kind (when the name alone is ambiguous). It's recommended to use tag IDs (coming from a `sifflet_tag` resource or data source) most of the time, but directly providing tag names can simplify some configurations. (see [below for nested schema](#nestedatt--tags))
- `timezone` (String) Timezone for the source. If empty, defaults to UTC.

### Read-Only

- `id` (String) The ID of the source.

<a id="nestedatt--parameters"></a>
### Nested Schema for `parameters`

Optional:

- `airflow` (Attributes) (see [below for nested schema](#nestedatt--parameters--airflow))
- `athena` (Attributes) (see [below for nested schema](#nestedatt--parameters--athena))
- `bigquery` (Attributes) (see [below for nested schema](#nestedatt--parameters--bigquery))
- `databricks` (Attributes) (see [below for nested schema](#nestedatt--parameters--databricks))
- `dbt` (Attributes) (see [below for nested schema](#nestedatt--parameters--dbt))
- `dbt_cloud` (Attributes) (see [below for nested schema](#nestedatt--parameters--dbt_cloud))
- `fivetran` (Attributes) (see [below for nested schema](#nestedatt--parameters--fivetran))
- `looker` (Attributes) (see [below for nested schema](#nestedatt--parameters--looker))
- `mssql` (Attributes) (see [below for nested schema](#nestedatt--parameters--mssql))
- `mysql` (Attributes) (see [below for nested schema](#nestedatt--parameters--mysql))
- `oracle` (Attributes) (see [below for nested schema](#nestedatt--parameters--oracle))
- `postgresql` (Attributes) (see [below for nested schema](#nestedatt--parameters--postgresql))
- `power_bi` (Attributes) (see [below for nested schema](#nestedatt--parameters--power_bi))
- `quicksight` (Attributes) (see [below for nested schema](#nestedatt--parameters--quicksight))
- `redshift` (Attributes) (see [below for nested schema](#nestedatt--parameters--redshift))
- `snowflake` (Attributes) (see [below for nested schema](#nestedatt--parameters--snowflake))
- `synapse` (Attributes) (see [below for nested schema](#nestedatt--parameters--synapse))
- `tableau` (Attributes) (see [below for nested schema](#nestedatt--parameters--tableau))

Read-Only:

- `source_type` (String) Source type (e.g bigquery, dbt, ...). This attribute is automatically set depending on which connection parameters are set.

<a id="nestedatt--parameters--airflow"></a>
### Nested Schema for `parameters.airflow`

Required:

- `host` (String) Airflow API host
- `port` (Number) Airflow API port


<a id="nestedatt--parameters--athena"></a>
### Nested Schema for `parameters.athena`

Required:

- `database` (String) Athena database name
- `datasource` (String) Athena datasource name
- `region` (String) AWS region in which the Athena database is located
- `role_arn` (String) AWS IAM role ARN to use for Athena queries
- `s3_output_location` (String) S3 location to store Athena query results
- `workgroup` (String) Athena workgroup name

Optional:

- `vpc_url` (String) VPC URL for Athena queries


<a id="nestedatt--parameters--bigquery"></a>
### Nested Schema for `parameters.bigquery`

Required:

- `dataset_id` (String) BigQuery dataset ID
- `project_id` (String) GCP project ID containing the BigQuery dataset.

Optional:

- `billing_project_id` (String) GCP billing project ID


<a id="nestedatt--parameters--databricks"></a>
### Nested Schema for `parameters.databricks`

Required:

- `catalog` (String) Databricks catalog name
- `host` (String) Databricks host
- `http_path` (String) Databricks HTTP path
- `port` (Number) Databricks server port
- `schema` (String) Databricks schema


<a id="nestedatt--parameters--dbt"></a>
### Nested Schema for `parameters.dbt`

Required:

- `project_name` (String) dbt project name
- `target` (String) dbt target name (the 'target' value in the profiles.yml file)


<a id="nestedatt--parameters--dbt_cloud"></a>
### Nested Schema for `parameters.dbt_cloud`

Required:

- `account_id` (String) dbt Cloud account ID
- `base_url` (String) dbt Cloud base URL
- `project_id` (String) dbt Cloud project ID

Optional:

- `job_definition_id` (String) dbt Cloud job definition ID


<a id="nestedatt--parameters--fivetran"></a>
### Nested Schema for `parameters.fivetran`

Optional:

- `host` (String) Fivetran host. Defaults to https://api.fivetran.com.


<a id="nestedatt--parameters--looker"></a>
### Nested Schema for `parameters.looker`

Required:

- `git_connections` (Attributes List) Configuration for the repositories storing LookML code. See [the Sifflet documentation](https://docs.siffletdata.com/docs/looker) for details. If you don't use LookML, pass an empty list. (see [below for nested schema](#nestedatt--parameters--looker--git_connections))
- `host` (String) URL of the Looker API for your instance. If your Looker instance is hosted at https://mycompany.looker.com, the API URL is https://mycompany.looker.com/api/4.0

<a id="nestedatt--parameters--looker--git_connections"></a>
### Nested Schema for `parameters.looker.git_connections`

Required:

- `auth_type` (String) Authentication type for the Git connection. Valid values are 'HTTP_AUTHORIZATION_HEADER', 'USER_PASSWORD' or 'SSH'. See the Sifflet docs for the meaning of each value.
- `secret_id` (String) Secret (credential) ID to use for authentication. The secret contents must match the chosen authentication type: access token for 'HTTP_AUTHORIZATION_HEADER' or 'USER_PASSWORD', or private SSH key for 'SSH'. See the Sifflet docs for more details.
- `url` (String) URL of the Git repository containing the LookML code.

Optional:

- `branch` (String) Branch of the Git repository to use. If omitted, the default branch is used.



<a id="nestedatt--parameters--mssql"></a>
### Nested Schema for `parameters.mssql`

Required:

- `database` (String) Database name
- `host` (String) Microsoft SQL Server hostname
- `port` (Number) Microsoft SQL Server port number
- `schema` (String) Schema name

Optional:

- `ssl` (Boolean, Deprecated) Use TLS to connect to Microsoft SQL Server.


<a id="nestedatt--parameters--mysql"></a>
### Nested Schema for `parameters.mysql`

Required:

- `database` (String) Database name
- `host` (String) MySQL server hostname
- `mysql_tls_version` (String) TLS version to use for MySQL connection. One of TLS_V_1_2 or TLS_V_1_3.
- `port` (Number) MySQL port number


<a id="nestedatt--parameters--oracle"></a>
### Nested Schema for `parameters.oracle`

Required:

- `database` (String) Database name
- `host` (String) Oracle server hostname
- `port` (Number) Oracle server port number
- `schema` (String) Schema name


<a id="nestedatt--parameters--postgresql"></a>
### Nested Schema for `parameters.postgresql`

Required:

- `database` (String) Database name
- `host` (String) PostgreSQL server hostname
- `port` (Number) PostgreSQL server port number
- `schema` (String) Schema name


<a id="nestedatt--parameters--power_bi"></a>
### Nested Schema for `parameters.power_bi`

Required:

- `client_id` (String) Azure AD client ID
- `tenant_id` (String) Azure AD tenant ID
- `workspace_id` (String) Power BI workspace ID


<a id="nestedatt--parameters--quicksight"></a>
### Nested Schema for `parameters.quicksight`

Required:

- `account_id` (String) AWS account ID
- `aws_region` (String) AWS region
- `role_arn` (String) AWS IAM role ARN used to access QuickSight (see Sifflet documentation for details)


<a id="nestedatt--parameters--redshift"></a>
### Nested Schema for `parameters.redshift`

Required:

- `database` (String) Database name
- `host` (String) Redshift server hostname
- `port` (Number) Redshift server port number
- `schema` (String) Schema name

Optional:

- `ssl` (Boolean) Use TLS to connect to Redshift. It's strongly recommended to keep this option enabled.


<a id="nestedatt--parameters--snowflake"></a>
### Nested Schema for `parameters.snowflake`

Required:

- `account_identifier` (String) Snowflake account identifier
- `database` (String) Database name
- `schema` (String) Schema name
- `warehouse` (String) Warehouse name, used by Sifflet to run queries


<a id="nestedatt--parameters--synapse"></a>
### Nested Schema for `parameters.synapse`

Required:

- `database` (String) Database name
- `host` (String) Azure Synapse server hostname
- `port` (Number) Azure Synapse server port number
- `schema` (String) Schema name


<a id="nestedatt--parameters--tableau"></a>
### Nested Schema for `parameters.tableau`

Required:

- `host` (String) Tableau Server hostname

Optional:

- `site` (String) Tableau Server site. If your Tableau environment is using the Default site, omit this field.



<a id="nestedatt--tags"></a>
### Nested Schema for `tags`

Optional:

- `id` (String) Tag ID. If provided, name and kind must be omitted.
- `kind` (String) Tag kind. If provided, name must be provided. Use this field for disambiguation when the tag name matches both a regular and a classification tag. Use 'Tag' to match a regular, user-managed tag. Use 'Classification' to match a tag that was automatically created by Sifflet. See the Sifflet documentation for more about tag types.
- `name` (String) Tag name. If provided, id must be omitted.

## Import

Import is supported using the following syntax:

The [`terraform import` command](https://developer.hashicorp.com/terraform/cli/commands/import) can be used, for example:

```shell
terraform import sifflet_source.example 'ad7b0951-318c-4950-932b-4614621b9bed'
```
