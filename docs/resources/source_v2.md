---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "sifflet_source_v2 Resource - terraform-provider-sifflet"
subcategory: ""
description: |-
  A Sifflet source. A source is any system that's monitored by Sifflet.
  The sifflet_source_v2 resource will create a source including all assets associated with that source, and discovery on future assets will be enabled.
  ~> Consider adding a lifecycle { prevent_destroy = true } to sifflet_source_v2 resources once they are correctly configured. Deleting a source deletes all associated data, including monitors on that source.
---

# sifflet_source_v2 (Resource)

A Sifflet source. A source is any system that's monitored by Sifflet.
		The sifflet_source_v2 resource will create a source including all assets associated with that source, and discovery on future assets will be enabled.

~> Consider adding a `lifecycle { prevent_destroy = true }` to `sifflet_source_v2` resources once they are correctly configured. Deleting a source deletes all associated data, including monitors on that source.

## Example Usage

```terraform
# The format of the credentials value must match what the source expects.
# See the Sifflet documentation for each source type for details
# about the credential value format.
data "sifflet_credentials" "example" {
  name = "example"
}

# A simple BigQuery data source.
resource "sifflet_source_v2" "example" {
  name = "example"
  parameters = {
    # Pass the parameter block that matches the source type.
    bigquery = {
      project_id         = "project_id"
      billing_project_id = "billing_project_id"
      credentials        = sifflet_credentials.example.name
    }
  }
}

# Example with more complex parameters.
resource "sifflet_source_v2" "complex" {
  name = "example"
  parameters = {
    snowflake = {
      account_identifier = "accountidentifier"
      warehouse          = "warehouse"
      credentials        = sifflet_credentials.example.name
      schedule           = "@daily"
    }
  }
  # The timezone can also be a timezone name, e.g. "Europe/Paris".
  timezone = "GMT"
}
```

<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `name` (String) Source name.
- `parameters` (Attributes) Connection parameters. Provide only one nested block depending on the source type. (see [below for nested schema](#nestedatt--parameters))

### Optional

- `timeouts` (Attributes) (see [below for nested schema](#nestedatt--timeouts))
- `timezone` (String) Timezone for the source. If empty, defaults to UTC.

### Read-Only

- `id` (String) The ID of the source.

<a id="nestedatt--parameters"></a>
### Nested Schema for `parameters`

Optional:

- `airflow` (Attributes) (see [below for nested schema](#nestedatt--parameters--airflow))
- `athena` (Attributes) (see [below for nested schema](#nestedatt--parameters--athena))
- `bigquery` (Attributes) (see [below for nested schema](#nestedatt--parameters--bigquery))
- `databricks` (Attributes) (see [below for nested schema](#nestedatt--parameters--databricks))
- `dbt` (Attributes) (see [below for nested schema](#nestedatt--parameters--dbt))
- `dbtcloud` (Attributes) (see [below for nested schema](#nestedatt--parameters--dbtcloud))
- `fivetran` (Attributes) (see [below for nested schema](#nestedatt--parameters--fivetran))
- `looker` (Attributes) (see [below for nested schema](#nestedatt--parameters--looker))
- `mssql` (Attributes) (see [below for nested schema](#nestedatt--parameters--mssql))
- `mysql` (Attributes) (see [below for nested schema](#nestedatt--parameters--mysql))
- `oracle` (Attributes) (see [below for nested schema](#nestedatt--parameters--oracle))
- `postgresql` (Attributes) (see [below for nested schema](#nestedatt--parameters--postgresql))
- `power_bi` (Attributes) (see [below for nested schema](#nestedatt--parameters--power_bi))
- `quicksight` (Attributes) (see [below for nested schema](#nestedatt--parameters--quicksight))
- `redshift` (Attributes) (see [below for nested schema](#nestedatt--parameters--redshift))
- `snowflake` (Attributes) (see [below for nested schema](#nestedatt--parameters--snowflake))
- `synapse` (Attributes) (see [below for nested schema](#nestedatt--parameters--synapse))
- `tableau` (Attributes) (see [below for nested schema](#nestedatt--parameters--tableau))

Read-Only:

- `source_type` (String) Source type (e.g bigquery, dbt, ...). This attribute is automatically set depending on which connection parameters are set.

<a id="nestedatt--parameters--airflow"></a>
### Nested Schema for `parameters.airflow`

Required:

- `credentials` (String) Name of the credentials used to connect to the source.
- `host` (String) Airflow server hostname
- `port` (Number) Airflow server port

Optional:

- `schedule` (String) Schedule for the source. Must be a valid cron expression. If empty, the source will only be refreshed when manually triggered.


<a id="nestedatt--parameters--athena"></a>
### Nested Schema for `parameters.athena`

Required:

- `datasource` (String) Athena datasource name
- `region` (String) AWS region in which the Athena instance is located
- `role_arn` (String) AWS IAM role ARN to use for Athena queries
- `s3_output_location` (String) The S3 location where Athena query results are stored
- `workgroup` (String) Athena workgroup name

Optional:

- `schedule` (String) Schedule for the source. Must be a valid cron expression. If empty, the source will only be refreshed when manually triggered.
- `vpc_url` (String) VPC URL for Athena connection


<a id="nestedatt--parameters--bigquery"></a>
### Nested Schema for `parameters.bigquery`

Required:

- `credentials` (String) Name of the credentials used to connect to the source.
- `project_id` (String) GCP project ID containing the BigQuery dataset.

Optional:

- `billing_project_id` (String) GCP billing project ID
- `schedule` (String) Schedule for the source. Must be a valid cron expression. If empty, the source will only be refreshed when manually triggered.


<a id="nestedatt--parameters--databricks"></a>
### Nested Schema for `parameters.databricks`

Required:

- `credentials` (String) Name of the credentials used to connect to the source.
- `host` (String) Databricks server host name
- `http_path` (String) Databricks HTTP path
- `port` (Number) Databricks server port

Optional:

- `schedule` (String) Schedule for the source. Must be a valid cron expression. If empty, the source will only be refreshed when manually triggered.


<a id="nestedatt--parameters--dbt"></a>
### Nested Schema for `parameters.dbt`

Required:

- `project_name` (String) Your dbt project name (the 'name' value in your dbt_project.yml file)
- `target` (String) Your dbt target name (the 'target' value in your profiles.yml file)


<a id="nestedatt--parameters--dbtcloud"></a>
### Nested Schema for `parameters.dbtcloud`

Required:

- `account_id` (String) Your dbt Cloud account ID
- `base_url` (String) Your dbt Cloud base URL
- `credentials` (String) Name of the credentials used to connect to the source.

Optional:

- `schedule` (String) Schedule for the source. Must be a valid cron expression. If empty, the source will only be refreshed when manually triggered.


<a id="nestedatt--parameters--fivetran"></a>
### Nested Schema for `parameters.fivetran`

Required:

- `credentials` (String) Name of the credentials used to connect to the source.

Optional:

- `host` (String) Fivetran host. Defaults to https://api.fivetran.com.
- `schedule` (String) Schedule for the source. Must be a valid cron expression. If empty, the source will only be refreshed when manually triggered.


<a id="nestedatt--parameters--looker"></a>
### Nested Schema for `parameters.looker`

Required:

- `credentials` (String) Name of the credentials used to connect to the source.
- `git_connections` (Attributes List) Configuration for the repositories storing LookML code. See [the Sifflet documentation](https://docs.siffletdata.com/docs/looker) for details. If you don't use LookML, pass an empty list. (see [below for nested schema](#nestedatt--parameters--looker--git_connections))
- `host` (String) URL of the Looker API for your instance. If your Looker instance is hosted at https://mycompany.looker.com, the API URL is https://mycompany.looker.com/api/4.0

Optional:

- `schedule` (String) Schedule for the source. Must be a valid cron expression. If empty, the source will only be refreshed when manually triggered.

<a id="nestedatt--parameters--looker--git_connections"></a>
### Nested Schema for `parameters.looker.git_connections`

Required:

- `auth_type` (String) Authentication type for the Git connection. Valid values are 'HTTP_AUTHORIZATION_HEADER', 'USER_PASSWORD' or 'SSH'. See the Sifflet docs for the meaning of each value.
- `secret_id` (String) Secret (credential) ID to use for authentication. The secret contents must match the chosen authentication type: access token for 'HTTP_AUTHORIZATION_HEADER' or 'USER_PASSWORD', or private SSH key for 'SSH'. See the Sifflet docs for more details.
- `url` (String) URL of the Git repository containing the LookML code.

Optional:

- `branch` (String) Branch of the Git repository to use. If omitted, the default branch is used.



<a id="nestedatt--parameters--mssql"></a>
### Nested Schema for `parameters.mssql`

Required:

- `credentials` (String) Name of the credentials used to connect to the source.
- `database` (String) MSSQL database name
- `host` (String) MSSQL server hostname
- `port` (Number) MSSQL server port

Optional:

- `schedule` (String) Schedule for the source. Must be a valid cron expression. If empty, the source will only be refreshed when manually triggered.
- `ssl` (Boolean, Deprecated) Whether to use SSL to connect to Microsoft SQL Server.


<a id="nestedatt--parameters--mysql"></a>
### Nested Schema for `parameters.mysql`

Required:

- `credentials` (String) Name of the credentials used to connect to the source.
- `database` (String) Database name
- `host` (String) MySQL server hostname
- `mysql_tls_version` (String) TLS version to use for MySQL connection. One of TLS_V_1_2 or TLS_V_1_3.
- `port` (Number) MySQL server port

Optional:

- `schedule` (String) Schedule for the source. Must be a valid cron expression. If empty, the source will only be refreshed when manually triggered.


<a id="nestedatt--parameters--oracle"></a>
### Nested Schema for `parameters.oracle`

Required:

- `credentials` (String) Name of the credentials used to connect to the source.
- `database` (String) Oracle database name
- `host` (String) Oracle server host name
- `port` (Number) Oracle server port

Optional:

- `schedule` (String) Schedule for the source. Must be a valid cron expression. If empty, the source will only be refreshed when manually triggered.


<a id="nestedatt--parameters--postgresql"></a>
### Nested Schema for `parameters.postgresql`

Required:

- `credentials` (String) Name of the credentials used to connect to the source.
- `database` (String) PostgreSQL database name
- `host` (String) PostgreSQL server host
- `port` (Number) PostgreSQL server port

Optional:

- `schedule` (String) Schedule for the source. Must be a valid cron expression. If empty, the source will only be refreshed when manually triggered.


<a id="nestedatt--parameters--power_bi"></a>
### Nested Schema for `parameters.power_bi`

Required:

- `client_id` (String) Your Azure AD client ID
- `credentials` (String) Name of the credentials used to connect to the source.
- `tenant_id` (String) Your Azure AD tenant ID

Optional:

- `schedule` (String) Schedule for the source. Must be a valid cron expression. If empty, the source will only be refreshed when manually triggered.


<a id="nestedatt--parameters--quicksight"></a>
### Nested Schema for `parameters.quicksight`

Required:

- `account_id` (String) Your AWS account ID
- `aws_region` (String) Your AWS region
- `role_arn` (String) The ARN for your QuickSight role

Optional:

- `schedule` (String) Schedule for the source. Must be a valid cron expression. If empty, the source will only be refreshed when manually triggered.


<a id="nestedatt--parameters--redshift"></a>
### Nested Schema for `parameters.redshift`

Required:

- `credentials` (String) Name of the credentials used to connect to the source.
- `host` (String) Redshift server hostname
- `port` (Number) Redshift server port

Optional:

- `schedule` (String) Schedule for the source. Must be a valid cron expression. If empty, the source will only be refreshed when manually triggered.
- `ssl` (Boolean) Whether to use SSL to connect to your Redshift server


<a id="nestedatt--parameters--snowflake"></a>
### Nested Schema for `parameters.snowflake`

Required:

- `account_identifier` (String) Snowflake account identifier
- `credentials` (String) Name of the credentials used to connect to the source.
- `warehouse` (String) Snowflake warehouse name

Optional:

- `schedule` (String) Schedule for the source. Must be a valid cron expression. If empty, the source will only be refreshed when manually triggered.


<a id="nestedatt--parameters--synapse"></a>
### Nested Schema for `parameters.synapse`

Required:

- `credentials` (String) Name of the credentials used to connect to the source.
- `host` (String) Synapse server host name
- `port` (Number) Synapse server port

Optional:

- `schedule` (String) Schedule for the source. Must be a valid cron expression. If empty, the source will only be refreshed when manually triggered.


<a id="nestedatt--parameters--tableau"></a>
### Nested Schema for `parameters.tableau`

Required:

- `credentials` (String) Name of the credentials used to connect to the source.
- `host` (String) Tableau Server hostname

Optional:

- `schedule` (String) Schedule for the source. Must be a valid cron expression. If empty, the source will only be refreshed when manually triggered.
- `site` (String) Tableau Server site. Leave empty if your Tableau environment is using the Default Site.



<a id="nestedatt--timeouts"></a>
### Nested Schema for `timeouts`

Optional:

- `create` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).
- `delete` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Setting a timeout for a Delete operation is only applicable if changes are saved into state before the destroy operation occurs.
- `read` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours). Read operations occur during any refresh or planning operation when refresh is enabled.
- `update` (String) A string that can be [parsed as a duration](https://pkg.go.dev/time#ParseDuration) consisting of numbers and unit suffixes, such as "30s" or "2h45m". Valid time units are "s" (seconds), "m" (minutes), "h" (hours).

## Import

Import is supported using the following syntax:

The [`terraform import` command](https://developer.hashicorp.com/terraform/cli/commands/import) can be used, for example:

```shell
terraform import sifflet_source_v2.example 'ad7b0951-318c-4950-932b-4614621b9bed'
```
